// vim: tw=79
= Clusters
:toc:

== Import Cluster

Import an existing Gluster or Ceph cluster.

Sample Request

----------
curl -XPOST -H "Authorization: Bearer
4b1b225d84104405b52a5646c997c22882aaeba094330c375cb7b0278e9d642a" -H "Content-Type: application/json" \
-d '{ "node_ids": ["7026f371-2d8c-4ad7-895f-4d4dcc70ff1c"], \
"sds_type":"ceph"}' http://127.0.0.1/api/1.0/ImportCluster 
----------

Sample Response

----------
Status: 202 Accepted

{ job_id: "3784922e33e8bec939be5e626e21a174" }
----------

The `job_id` can be used to poll the status of the job.
The import cluster action queued a job in etcd which will be picked up by the
node agent and processed.

== List Clusters

List available clusters

Sample Request

----------
curl -XGET -H "Authorization: Bearer
4b1b225d84104405b52a5646c997c22882aaeba094330c375cb7b0278e9d642a" -H "Content-Type: application/json" \
http://127.0.0.1/api/1.0/GetClusterList 
----------

Sample Response

----------
Status: 200 OK
{
	"clusters": [{
		"fsid": "64d779e6-491e-4998-a805-1252bbd5a899",
		"integration_id": "64d779e6-491e-4998-a805-1252bbd5a899",
		"name": "ceph",
		"sds_name": "ceph",
		"sds_version": "10.2.5",
		"cluster_id": "64d779e6-491e-4998-a805-1252bbd5a899",
		"pools": {
			"14": {
				"pool_name": "dummy",
				"type": "replicated",
				"used": "0",
				"erasure_code_profile": "",
				"min_size": "2",
				"percent_used": "0",
				"pg_num": "128",
				"pool_id": "14"
			},
			"4": {
				"min_size": "2",
				"percent_used": "0",
				"type": "replicated",
				"used": "58",
				"rbds": {
					"mmrbd1": {
						"features": "layering, exclusive-lock, object-map, fast-diff, deep-flatten",
						"flags": "",
						"format": "2",
						"name": "mmrbd1",
						"order": "22",
						"pool_id": "4",
						"size": "128",
						"block_name_prefix": "rbd_data.1e3f238e1f29"
					}
				},
				"erasure_code_profile": "",
				"pg_num": "128",
				"pool_id": "4",
				"pool_name": "test_pool"
			}
		}
	}]
}
----------




